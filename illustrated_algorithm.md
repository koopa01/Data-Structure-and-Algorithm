# 第1章 算法简介
## 1.二分查找
    一般而言，对于包含n个元素的列表，用二分查找最多需要log2n步，而简单查找最多需要n步。
## 2.大O表示法 
    1.指的并非以秒为单位的速度。大O表示法让你能够比较操作数，它指出了算法运行时间的增速。
    算法的速度指的并非时间，而是操作数的增速。

    2.
    O(log n)，也叫对数时间，这样的算法包括二分查找。
    O(n)，也叫线性时间，这样的算法包括简单查找。
    O(n ＊ log n)，快速排序——一种速度较快的排序算法。
    O(n2)，选择排序——一种速度较慢的排序算法。
    O(n! )，旅行商问题的解决方案——一种非常慢的算法。

    3.计算机科学领域非常著名的旅行商问题，其计算时间增加得非常快:
    这位旅行商要前往这5个城市，同时要确保旅程最短。为此，可考虑前往这些城市的各种可能顺序。
    对于每种顺序，他都计算总旅程，再挑选出旅程最短的路线。5个城市有120种不同的排列方式。
    因此，在涉及5个城市时，解决这个问题需要执行120次操作。
    涉及6个城市时，需要执行720次操作（有720种不同的排列方式）。
    涉及7个城市时，需要执行5040次操作！

# 第2章 选择排序
    1.两种最基本的数据结构——数组和链表
    2.还记得二分查找吗？它只能用于有序元素列表。本章将介绍选择排序。
    3.需要将数据存储到内存时，你请求计算机提供存储空间，计算机给你一个存储地址。需要存储多项数据时，有两种基本方式——数组和链表。但它们并非都适用于所有的情形，因此知道它们的差别很重要。接下来介绍数组和链表以及它们的优缺点。
## 数组和链表
    1.使用数组意味着所有待办事项在内存中都是相连的（紧靠在一起的）。
    2.在数组中添加新元素也可能很麻烦。如果没有了空间，就得移到内存的其他地方，因此添加新元素的速度会很慢。一种解决之道是“预留座位”：即便当前只有3个待办事项，也请计算机提供10个位置，以防需要添加待办事项。
    3.它存在如下两个缺点:
        你额外请求的位置可能根本用不上，这将浪费内存。你没有使用，别人也用不了。
        待办事项超过10个后，你还得转移。
    因此，这种权宜措施虽然不错，但绝非完美的解决方案。对于这种问题，可使用链表来解决。
## 链表
    1.链表中的元素可存储在内存的任何地方。
    2.链表的每个元素都存储了下一个元素的地址，从而使一系列随机的内存地址串在一起。
        在链表中添加元素很容易：只需将其放入内存，并将其地址存储到前一个元素中。
        链表的优势在插入元素方面
## 数组
    1.需要同时读取所有元素时，链表的效率很高：你读取第一个元素，根据其中的地址再读取第二个元素，以此类推。
    但如果你需要跳跃，链表的效率真的很低。
    2.数组与此不同：你知道其中每个元素的地址。
        需要随机地读取元素时，数组的效率很高，因为可迅速找到数组的任何元素。
             | 数组 | 链表
        读取 | O(1) | O(n)
        插入 | O(n) | o(1)
## 在中间插入与删除
    1.需要在中间插入元素时，数组和链表哪个更好呢？
        使用链表时，插入元素很简单，只需修改它前面的那个元素指向的地址。
        而使用数组时，则必须将后面的元素都向后移。
        如果没有足够的空间，可能还得将整个数组复制到其他地方！因此，当需要**在中间插入元素**时，**链表**是更好的选择。
    2.如果你要删除元素呢？
        **链表**也是更好的选择，因为只需修改前一个元素指向的地址即可。
        而使用数组时，删除元素后，必须将后面的元素都向前移。
             | 数组 | 链表
        读取 | O(1) | O(n)
        插入 | O(n) | O(1)
        删除 | O(n) | O(1)
    3.需要指出的是，仅当能够立即访问要删除的元素时，删除操作的运行时间才为O(1)。
    通常我们都记录了链表的第一个元素和最后一个元素，因此删除这些元素时运行时间为O(1)。
## 比较
    1.数组用得很多，因为它支持随机访问。
        链表只能顺序访问：要读取链表的第十个元素，得先读取前九个元素，并沿链接找到第十个元素。
        随机访问意味着可直接跳到第十个元素。
    2.数组的元素都在一起。
    3.链表的元素是分开的，其中每个元素都存储了下一个元素的地址。
    4.数组的读取速度很快。
    5。链表的插入和删除速度很快。
## 选择排序
    选择排序是一种灵巧的算法，但其速度不是很快。

# 第3章 递归
    递归只是让解决方案更清晰，并没有性能上的优势。
    Leigh Caldwell在Stack Overflow上说的一句话：“如果使用循环，程序的性能可能更高；如果使用递归，程序可能更容易理解。如何选择要看什么对你来说更重要。”
## 基线条件和递归条件
    1.每个递归函数都有两部分：基线条件（base case）和递归条件（recursive case）。
        递归条件指的是函数何时调用自己
        基线条件则指的是函数何时不再调用自己，从而避免形成无限循环。
    2.所有函数调用都进入调用栈。
    3.调用栈可能很长，这将占用大量的内存。

# 第4章 快速排序
    学习分而治之（divide and conquer, D&C）。有时候可能会遇到使用任何已知的算法都无法解决的问题。
        优秀的算法学家遇到这种问题时，不会就此放弃，而是尝试使用掌握的各种问题解决方法来找出解决方案。分而治之是第一种通用的问题解决方法。
    学习快速排序——一种常用的优雅的排序算法。快速排序使用分而治之的策略。
## 分而治之
    如何将一块地均匀地分成方块，并确保分出的方块是最大的呢？
        (1) 找出基线条件，这种条件必须尽可能简单。
        (2) 不断将问题分解（或者说缩小规模），直到符合基线条件。
    首先，找出基线条件。
        可以将这块地分成两个短边长的正方块。现在需要找出递归条件，这正是D&C的用武之地。根据D&C的定义，每次递归调用都必须缩小问题的规模。
        余下一小块地。现在是顿悟时刻：何不对余下的那一小块地使用相同的算法呢？
        直到找出最小的无余数的方块，则为最后的解。
            例：给定一个数字数组。将这些数字相加，并返回结果。
                ```
                def sum_number(num):
                    if len(num) > 1:    #基线条件：数组中只有一个元素时停止
                        s = num.pop(0) + sum_number(num)    #将问题分解为第一个数加剩下的所有数
                        return s
                    else:
                        s = num.pop(0)
                        return s
                print('sum = ', sum_number([1,2,3,4,5]))
                ```
            编写涉及数组的递归函数时，基线条件通常是数组为空或只包含一个元素。陷入困境时，请检查基线条件是不是这样的。
## 快速排序
    1.标准库中的函数qsort实现的就是快速排序。快速排序也使用了D&C。
    2.首先，从数组中选择一个元素，这个元素被称为基准值  （pivot）。[33,1,7,15,10]
      接下来，找出比基准值小的元素以及比基准值大的元素。[1,7,15,10]+[33]+[]
      这里只是进行了分区，得到的两个子数组是无序的。如果子数组是有序的，就可以合并得到一个有序的数组：左边的数组+基准值+右边的数组。
      只要对这两个子数组进行快速排序，再合并结果，就能得到一个有序数组！ quicksort([1,7,15,10])+[33]+quicksort([])
        (1) 选择基准值。
        (2) 将数组分成两个子数组：小于基准值的元素和大于基准值的元素。
        (3) 对这两个子数组进行快速排序。
    这种思想也叫归纳证明
    ```
    def quicksort(array):
        if len(array) < 2:
            return array    # 基线条件：为空或只有一个元素的数组是有序的
        else:
            pivot = array[0]
            less = [i for i in array[1:] if i <= pivot]    # 小于等于基准值的子数组
            greater = [i for i in array[1:] if i > pivot]    # 大于基准值的子数组
            return quicksort(less) + [pivot] + quicksort(greater)
    print(quicksort([1,7,33,15,10]))
    ```
## 比较合并排序和快速排序
    1.还有一种名为合并排序（merge sort）的排序算法，其运行时间为O(n log n)，比选择排序快得多！快速排序的情况比较棘手，在最糟情况下，其运行时间为O(n2)。
    与选择排序一样慢！但这是最糟情况。在平均情况下，快速排序的运行时间为O(n log n)。
    2.有时候，常量的影响可能很大，对快速查找和合并查找来说就是如此。
    快速查找的常量比合并查找小，因此如果它们的运行时间都为O(n log n)，快速查找的速度将更快。
    3.实际上，快速查找的速度确实更快，因为相对于遇上最糟情况，它遇上平均情况的可能性要大得多。
        层数为O(log n)（用技术术语说，调用栈的高度为O(log n)），而每层需要的时间为O(n)。因此整个算法需要的时间为O(n) ＊ O(log n)=O(n log n)。这就是最佳情况。
        在最糟情况下，有O(n)层，因此该算法的运行时间为O(n) ＊ O(n)=O(n2)。
    4.只要你每次都随机地选择一个数组元素作为基准值，快速排序的平均运行时间就将为O(n log n)。快速排序是最快的排序算法之一，也是D&C典范。

# 第5章 散列表(hash table)
    散列表的内部机制：实现、冲突和散列函数。
    假设你在一家杂货店上班。有顾客来买东西时，你得在一个本子中查找价格。
        如果本子的内容不是按字母顺序排列的，你可能为查找苹果（apple）的价格而浏览每一行，这需要很长的时间。
        此时你使用的是第1章介绍的简单查找，需要浏览每一行。这需要时间O(n)。
        如果本子的内容是按字母顺序排列的，可使用二分查找来找出苹果的价格，这需要的时间更短，为O(log n)。
        若有一名能够记住所有商品价格的雇员，这样你就不用查找了，报出任何商品的价格的时间都为O(1)。
    散列表适合用于：
        1.模拟映射关系；
        2.防止重复； #冲突
        3.缓存/记住数据，以免服务器再通过处理来生成它们。

## 散列函数
    散列函数“将输入映射到数字”。是无论你给它什么数据，它都还你一个数字。
    散列函数准确地指出了价格的存储位置，你根本不用查找！
    散列函数总是将同样的输入映射到相同的索引。
        1.每次你输入avocado，得到的都是同一个数字。因此，可首先使用它来确定将鳄梨的价格存储在什么地方，并在以后使用它来确定鳄梨的价格存储在什么地方。
        2.散列函数将不同的输入映射到不同的索引。avocado映射到索引4, milk映射到索引0。每种商品都映射到数组的不同位置，让你能够将其价格存储到这里。
        3.散列函数知道数组有多大，只返回有效的索引。如果数组包含5个元素，散列函数就不会返回无效索引100。
    于是，结合使用散列函数和数组创建了一种被称为散列表（hash table）的数据结构。
        Python提供的散列表实现为字典。
    ```
    book['apple'] = 0.67
    book['milk'] = 1.49
    book['avocado'] =  1.49
    print(book)
    #{'avocado': 1.49, 'apple': 0.67, 'milk': 1.49}
    ```
        散列表由键和值组成。在前面的散列表book中，键为商品名，值为商品价格。散列表将键映射到值。
## 将散列表用于查找
    假设要创建一个类似手机的电话簿，将姓名映射到电话号码。该电话簿需要提供如下功能。
        1.添加联系人及其电话号码。
        2.通过输入联系人来获悉其电话号码。
    这非常适合使用散列表来实现！在下述情况下，使用散列表是很不错的选择。
        1.创建映射。
        2.查找。
    ```
    phone_book = {}
    phone_book['jenny'] = 8675309
    phone_book['emergency'] = 911

    print(phone_book['jenny'])
    # 8675309
    ```
        DNS解析（DNSresolution），散列表是提供这种功能的方式之一。
## 防止重复
    假设你负责管理一个投票站。显然，每人只能投一票，但如何避免重复投票呢？有人来投票时，你询问他的全名，并将其与已投票者名单进行比对。
    ```
    voted = {}
    def check_voter(name):
        if voted.get(name):
            print('kick him out')
        else:
            voted[name] = true
            print('let them vote')
    ```
    使用散列表来检查是否重复，速度非常快。
## 将散列表用作缓存
    当你访问Facebook的页面时，它首先检查散列表中是否存储了该页面。
    ```
    cache = {}
    def get_page(url):
        if cache.get(url):
            return cache[url]   #返回缓存的数据
        else:
            data = get_data_from_server(url)
            cache[url] = data   #先将数据保存到缓存中
            return data
    ```
## 冲突
    若水果店存储数据，建立数组存储单词A-Z开头的水果，按字母表顺序分配数组的位置。
        若已经存了apple，还想再存avocado，则造成冲突。
        所以，如果两个键映射到了同一个位置，就在这个位置存储一个链表。
    散列函数很重要。前面的散列函数将所有的键都映射到一个位置，而最理想的情况是，散列函数将键均匀地映射到散列表的不同位置。
    如果散列表存储的链表很长，散列表的速度将急剧下降。然而，如果使用的散列函数很好，这些链表就不会很长！
## 性能
    在平均情况下，散列表执行各种操作的时间都为O(1)。
    在最糟情况下，散列表所有操作的运行时间都为O(n)。
    在使用散列表时，避开最糟情况至关重要，需要避免冲突。需要有：
        1.较低的填装因子；  #装填因子为数组中被占用（已存储）的位置数/总位置数，最好为0.7。
            填装因子大于1意味着装因子过大，需要在散列表中添加位置，这被称为调整长度（resizing）。
                为此，你首先创建一个更长的新数组：通常将数组增长一倍。
                接下来，需要使用函数hash将所有的元素都插入到这个新的散列表中。
            填装因子越低，发生冲突的可能性越小，散列表的性能越高。
        2.良好的散列函数。
            良好的散列函数让数组中的值呈均匀分布。
            糟糕的散列函数让值扎堆，导致大量的冲突。
            SHA函数
## 总结
    散列表是一种功能强大的数据结构，其操作速度快，还能让你以不同的方式建立数据模型。你可能很快会发现自己经常在使用它。
        1.你可以结合散列函数和数组来创建散列表。
        2.冲突很糟糕，你应使用可以最大限度减少冲突的散列函数。
        3.散列表的查找、插入和删除速度都非常快。
        4.散列表适合用于模拟映射关系。
        5.一旦填装因子超过0.7，就该调整散列表的长度。
        6.散列表可用于缓存数据（例如，在Web服务器上）。
        7.散列表非常适合用于防止重复。

# 第6章 广度优先搜索
    假设你居住在旧金山，要从双子峰前往金门大桥。你想乘公交车前往，并希望换乘最少。
        金门大桥未突出，因此一步无法到达那里。两步能吗？金门大桥也未突出，因此两步也到不了。三步呢？
        还有其他前往金门大桥的路线，但它们更远（需要四步）。
    这个算法发现，前往金门大桥的最短路径需要三步。这种问题被称为最短路径问题（shorterst-path problem）。
        你经常要找出最短路径，这可能是前往朋友家的最短路径，也可能是国际象棋中把对方将死的最少步数。解决最短路径问题的算法被称为广度优先搜索。
## 图是什么
    1.图由节点（node）和边（edge）组成。
    2.一个节点可能与众多节点直接相连，这些节点被称为邻居。
    3.根据关系远近，例如，朋友是一度关系，朋友的朋友是二度关系。
    图用于模拟不同的东西是如何相连的。
## 广度优先搜索
    第一类问题：从节点A出发，有前往节点B的路径吗？（在你的人际关系网中，有芒果销售商吗？）
    第二类问题：从节点A出发，前往节点B的哪条路径最短？（哪个芒果销售商与你的关系最近？）
        一度关系胜过二度关系，二度关系胜过三度关系，以此类推。因此，你应先在一度关系中搜索，确定其中没有芒果销售商后，才在二度关系中搜索。
    1.你按顺序依次检查名单中的每个人，看看他是否是芒果销售商。
    2.这将先在一度关系中查找，再在二度关系中查找，因此找到的是关系最近的芒果销售商。
    3.广度优先搜索不仅查找从A到B的路径，而且找到的是最短的路径。
        # 需要按添加顺序查找，才能实现这样的目的 —— 队列
## 队列
    队列是一种先进先出（First In First Out, FIFO）的数据结构，而栈是一种后进先出（Last InFirst Out, LIFO）的数据结构。
    入队、出队 = 压入、弹出
## 实现图
    图由多个节点组成。每个节点都与邻近节点相连，如果表示类似于“你→Bob”这样的关系呢？
    好在你知道的一种结构让你能够表示这种关系，它就是散列表！
    记住，散列表让你能够将键映射到值。在这里，你要将节点映射到其所有邻居。
    ```
    graph = {}
    graph['you'] = ['alice','bob','claire']
    graph['bob'] = ['anuj','peggy']
    graph['alice'] = ['peggy']
    graph['claire'] = ['thom','jonny']
    graph['anuj'] = []
    graph['peggy'] = []
    graph['thom'] = []
    graph['jonny'] = []
    ```
    # 'you'被映射到了一个数组，因此graph["you"]是一个数组，其中包含了“你”的所有邻居。
    # 散列表是无序的，因此添加键—值对的顺序无关紧要。
    Anuj、Peggy、Thom和Jonny都没有邻居，这是因为虽然有指向他们的箭头，但没有从他们出发指向其他人的箭头。
        这被称为有向图（directed graph），其中的关系是单向的。因此，Anuj是Bob的邻居，但Bob不是Anuj的邻居。
        无向图（undirected graph）没有箭头，直接相连的节点互为邻居。
## 实现算法
    1.创建一个队列，用于储存要检查的人
    2.从队列中弹出一个人
    3.检查这个人是否是芒果销售商
    4.判定：a.是，大功告成
            b.否，将这个人的所有邻居加入队列
    5.回到第2步
    6.如果队列为空，说明人际关系网中没有芒果销售商
    ```
    from collections import deque

    search_queue = deque()  #创建一个双端队列
    search_queue += graph['you']    #graph["you"]是一个数组，其中包含你的所有邻居，如["alice", "bob","claire"]。

    while search_queue:     #只要队列不为空
        person = search_queue.popleft()     #就去出其中的第一个人
        if person_is_seller(person):    #检查是否是芒果销售商
            print(person + 'is a mango seller!')
            return True
        else:
            search_queue += graph[person]   #不是芒果销售商，将这个人的朋友都加入搜索队列
    return False    #如果到达这里，说明队列中没认识芒果销售商

    def person_is_seller(name):
        return name[-1] == 'm'  #这个函数检查人的姓名是否以m结尾：如果是，他就是芒果销售商。(只是举例)
    ```
    这个算法将不断执行，直到满足以下条件之一：
        1.找到一位芒果销售商；
        2.队列变成空的，这意味着你的人际关系网中没有芒果销售商。
    有一个问题：Peggy既是Alice的朋友又是Bob的朋友，因此她将被加入队列两次：一次是在添加Alice的朋友时，另一次是在添加Bob的朋友时。
        因此，检查完一个人后，应将其标记为已检查，且不再检查他。
        如果不这样做，就可能会导致无限循环。
    ```
    from collections import deque

    def search(name):
        search_queue = deque()
        search_queue += graph[name]
        searched = []    # 这数组用于记录已经被检查过的人

        while search_queue:
            person = search_queue.popleft()
            if person not in searched:  #仅当这个人没被检查过时才检查
                if person_is_seller(person):
                    print(person + 'is a mango seller!')
                    return True
                else:
                    search_queue += graph[person] 
                    search.append(person)   #标记这个人被检查过
        return False    

    def person_is_seller(name):
        return name[-1] == 'm'

    search('you')
    ```
### 运行时间
    如果你在你的整个人际关系网中搜索芒果销售商，就意味着你将沿每条边前行（记住，边是从一个人到另一个人的箭头或连接），因此运行时间至少为O（边数）。
    你还使用了一个队列，其中包含要检查的每个人。将一个人添加到队列需要的时间是固定的，即为O(1)，因此对每个人都这样做需要的总时间为O(人数)。
        所以，广度优先搜索的运行时间为O(人数+边数)，这通常写作O(V+E)，其中V为顶点（vertice）数，E为边数。
### 拓扑排序
    如果任务A依赖于任务B，在列表中任务A就必须在任务B后面。从某种程度上说，这种列表是有序的。
    这被称为拓扑排序，使用它可根据图创建一个有序列表。
        例如：你正在规划一场婚礼，并有一个很大的图，其中充斥着需要做的事情，但却不知道要从哪里开始。这时就可使用拓扑排序来创建一个有序的任务列表。
        例如：家谱。这种图被称为树。树是一种特殊的图，其中没有往后指的边。
## 小结
    1.广度优先搜索指出是否有从A到B的路径。
    2.如果有，广度优先搜索将找出最短路径。
    3.面临类似于寻找最短路径的问题时，可尝试使用图来建立模型，再使用广度优先搜索来解决问题。
    4.有向图中的边为箭头，箭头的方向指定了关系的方向，例如，rama→adit表示rama欠adit钱。
    5.无向图中的边不带箭头，其中的关系是双向的，例如，ross - rachel表示“ross与rachel约会，而rachel也与ross约会”。
    6.队列是先进先出（FIFO）的。❑ 栈是后进先出（LIFO）的。
    7.你需要按加入顺序检查搜索列表中的人，否则找到的就不是最短路径，因此搜索列表必须是队列。
    8.对于检查过的人，务必不要再去检查，否则可能导致无限循环。

# 第7章 狄克斯特拉算法
    1.介绍加权图——提高或降低某些边的权重。
    2.介绍狄克斯特拉算法，找出加权图中前往X的最短路径。
    3.介绍图中的环，它导致狄克斯特拉算法不管用。
        前一章使用了广度优先搜索，它找出的是段数最少的路径。如果你要找出最快的路径，可使用狄克斯特拉算法（Dijkstra's algorithm）。
    狄克斯特拉算法包含4个步骤:
        (1) 找出“最便宜”的节点，即可在最短时间内到达的节点。
        (2) 更新该节点的邻居的开销，其含义将稍后介绍。
        (3) 重复这个过程，直到对图中的每个节点都这样做了。
        (4) 计算最终路径。
### 第一步
    找出最便宜的节点。你站在起点，不知道该前往节点A还是前往节点B。前往这两个节点都要多长时间呢？
        前往节点A需要6分钟，而前往节点B需要2分钟。至于前往其他节点，你还不知道需要多长时间。
        由于你还不知道前往终点需要多长时间，因此你假设为无穷大。
        节点B是最近的——2分钟就能达到。
        节点 | 耗时
         A   | 6
         B   | 2
        终点 | 无穷
### 第二步
    计算经节点B前往其各个邻居所需的时间。
        你刚找到了一条前往节点A的更短路径！经由节点B前往节点A只需5分钟！
        1.前往节点A的更短路径（时间从6分钟缩短到5分钟）；
        2.前往终点的更短路径（时间从无穷大缩短到7分钟）。
        节点 | 耗时
         A   | ~~6~~5
         B   | 2
        终点 | 7
### 第三步
    重复第一步：找出可在最短时间内前往的节点。
        你对节点B执行了第二步，除节点B外，可在最短时间内前往的节点是节点A。

    重复第二步：更新节点A的所有邻居的开销。
        你发现前往终点的时间为6分钟！
        你对每个节点都运行了狄克斯特拉算法（无需对终点这样做）。
            前往节点B需要2分钟；
            前往节点A需要5分钟；
            前往终点需要6分钟。
### 最后一步——计算最终路径
## 广度优先搜索和狄克斯特拉算法区别
    在前一章，你使用了广度优先搜索来查找两点之间的最短路径，那时“最短路径”的意思是段数最少。
    在狄克斯特拉算法中，你给每段都分配了一个数字或权重，因此狄克斯特拉算法找出的是总权重最小的路径。
        这里重述一下，狄克斯特拉算法包含4个步骤。
            (1) 找出最便宜的节点，即可在最短时间内前往的节点。
            (2) 对于该节点的邻居，检查是否有前往它们的更短路径，如果有，就更新邻居开销。
            (3) 重复这个过程，直到对图中的每个节点都这样做了。
            (4) 计算最终路径。
## 术语
    权重（weight）：狄克斯特拉算法用于每条边都有关联数字的图，这些数字称为权重。
    加权图（weighted graph）：带权重的图称为加权图，不带权重的图称为非加权图（unweightedgraph）。
        要计算非加权图中的最短路径，可使用广度优先搜索。要计算加权图中的最短路径，可使用狄克斯特拉算法。
    **图还可能有环**:在无向图中，每条边都是一个环。狄克斯特拉算法只适用于有向无环图（directed acyclicgraph, DAG）。
        绕环的路径不可能是最短的路径。
## 换钢琴
    狄克斯特拉算法背后的关键理念：找出图中最便宜的节点，并确保没有到该节点的更便宜的路径！仅在没有负权边时才成立。
    如果有负权边，就不能使用狄克斯特拉算法。
    在包含负权边的图中，要找出最短路径，可使用另一种算法——贝尔曼-福德算法（Bellman-Fordalgorithm）
## 实现
    要编写解决这个问题的代码，需要三个散列表。graph、costs、parents。随着算法的进行，你将不断更新散列表costs和parents。
        1.将节点的所有邻居都存储在散列表中。
        ```
        graph = {}

        graph['start'] = {}    # 起始节点
        graph['start']['a'] = 6    # 起始节点的边的权重，graph['start']包含graph['a']、graph['b']
        graph['start']['b'] = 2
        # print(graph['start'].keys())  -- ['a','b']

        graph['a'] = {}    # 添加其他节点及其邻居
        graph['a']['fin'] = 1

        graph['b'] = {}
        graph['b']['a'] = 3
        graph['b']['fin'] = 5

        graph['fin'] = {}    # 终点没有任何邻居
        ```
        2.用一个散列表来存储每个节点的开销
        ```
        infinity = float('inf')
        costs = {}
        costs['a'] = 6
        costs['b'] = 2
        costs['fin'] = infinity
        ```
        3.存储父节点的散列表
        ```
        parents = {}
        parents['a'] = 'start'
        parents['b'] = 'start'
        parents['fin'] = None
        ```
        4.你需要一个数组，用于记录处理过的节点，因为对于同一个节点，你不用处理多次。
        ```
        processed = []
        ```
        5.算法
            只要还有要处理的节点
            获取离起点最近的节点
            更新其邻居的开销
            如果有邻居的开销被更新，同时更新父节点
            将该结点标记为处理过  ——>  第一步
        ```
        node = find_lowest_cost_node(costs)     # 在未处理的节点中找出开销最小的节点
        while node is not None:     # 在所有节点都被处理后结束
            cost = costs[node]
            neighbors = graph[node]
            for n in neighbors.keys():      # 遍历当前节点的所有邻居
                new_cost = cost + neighbors[n]
                if costs[n] > new_cost:     # 如果经当前节点前往该邻居更近
                    costs[n] = new_cost     # 就更新该邻居开销
                    parents[n] = node       # 同时该邻居的父节点设置为当前节点
            processed.append(node)          # 将当前节点标记为处理过
            node = find_lowest_cost_node(costs)     # 找出接下来要处理的节点，并循环

        def find_lowest_cost_node(costs):
            lowest_cost = float('inf')
            lowest_cost_node = None
            for node in costs:      # 遍历所有节点
                cost = costs[node]
                if cost < lowest_cost and node not in processed:    # 如果当前节点的开销更低且未处理过
                    lower_cost = cost       # 就将其视为开销最低的节点
                    lowest_cost_node = node
            return lowest_cost_node
        ```
## 小结
    1.广度优先搜索用于在非加权图中查找最短路径。
    2.狄克斯特拉算法用于在加权图中查找最短路径。
    3.仅当权重为正时狄克斯特拉算法才管用。
    4.如果图中包含负权边，请使用贝尔曼-福德算法。

# 第8章 贪婪算法
    识别NP完全问题(无快速算法)
    近似算法，可快速找到NP完全问题的近似解
    贪婪策略——一种非常简单的问题解决策略
## 集合覆盖问题
    1.贪婪算法很简单：每步都采取最优的做法。就是你每步都选择局部最优解。
    2.贪婪策略不能总是获得最优解，但会非常接近。
    假设你办了个广播节目，要让全美50个州的听众都收听得到。为此，你需要决定在哪些广播台播出。在每个广播台播出都需要支付费用，因此你力图在尽可能少的广播台播出。
        如何找出覆盖全美50个州的最小广播台集合呢？
            (1) 列出每个可能的广播台集合，这被称为幂集（power set）。可能的子集有2^n个。
            (2) 在这些集合中，选出覆盖全美50个州的最小集合。
### 近似算法：
    在获得精确解需要的时间太长时，可使用近似算法。
    判断近似算法优劣的标准如下：
        1.速度有多快；
        2.得到的近似解与最优解的接近程度。
    1.准备工作
        ```
        states_needed = set(['mt','wa','or','id','nv','ut','ca','az'])

        stations = {}
        stations['kone'] = set(['id','nv','ut'])
        stations['ktwo'] = set(['wa','id','mt'])
        stations['kthree'] = set(['or','vn','ca'])
        stations['kfour'] = set(['nv','ut'])
        stations['kfive'] = set(['az','ca'])

        final_stations = set
        ```
    2.计算答案
        ```
        while states_needed:
            best_station = None
            states_covered = set()

            for station,states_for_station in stations.items:
                covered = states_needed & states_for_station    #它包含当前广播台覆盖的一系列还未覆盖的州

                if len(covered) > len(states_covered):
                    best_station = station
                    states_covered = covered

            final_stations.add(best_station)
            states_needed -= states_covered
        # print(final_stations)
        # set(['ktwo','kthree','kone','kfive'])
        ```
## NP完全问题
    1.旅行商问题和集合覆盖问题有一些共同之处：你需要计算所有的解，并从中选出最小/最短的那个。
        这两个问题都属于NP完全问题。
    2.NP完全问题的简单定义是，以难解著称的问题，如旅行商问题和集合覆盖问题。
    3.如何识别NP完全问题:
        1.元素较少时算法的运行速度非常快，但随着元素数量的增加，速度会变得非常慢。
        2.涉及“所有组合”的问题通常是NP完全问题。
        3.不能将问题分成小问题，必须考虑各种可能的情况。这可能是NP完全问题。
        4.如果问题涉及序列（如旅行商问题中的城市序列）且难以解决，它可能就是NP完全问题。
        5.如果问题涉及集合（如广播台集合）且难以解决，它可能就是NP完全问题。
        6.如果问题可转换为集合覆盖问题或旅行商问题，那它肯定是NP完全问题。
## 小结
    1.贪婪算法寻找局部最优解，企图以这种方式获得全局最优解。
    2.对于NP完全问题，还没有找到快速解决方案。
    3.面临NP完全问题时，最佳的做法是使用近似算法。
    4.贪婪算法易于实现、运行速度快，是不错的近似算法。

# 第9章 动态规划
    将问题分成小问题，并先着手解决这些小问题。
## 背包问题
    对于背包问题，你先解决小背包（子背包）问题，再逐步解决原来的问题。
        1.每个动态规划算法都从一个网格开始
        2.网格的各行为商品，各列为不同容量（1～4磅）的背包。所有这些列你都需要，因为它们将帮助你计算子背包的价值。
        3.网格最初是空的。将填充其中的每个单元格，网格填满后，就找到了问题的答案！
                1       2       3       4
    吉他      1500G   1500G   1500G   1500G
    音响      1500G   1500G   1500G   3000S
    笔记本电脑 1500G   1500G   2000L   3500GL
    cell[i][j] = 两者中较大值{
                    1.第一个单元格的值(cell[i-1][j])
                    2.当前商品的价值+剩余空间的价值(cell[i-1][j-当前商品重量])
                    }
    合并两个子问题的解来得到更大问题的解。

    可以逐列而不是逐行填充网格
    使用动态规划时，要么考虑拿走整件商品，要么考虑不拿，而没法判断该不该拿走商品的一部分。
        但使用贪婪算法可轻松地处理这种情况！首先，尽可能多地拿价值最高的商品；如果拿光了，再尽可能多地拿价值次高的商品，以此类推。
    动态规划功能强大，它能够解决子问题并使用这些答案来解决大问题。但仅当每个子问题都是离散的，即不依赖于其他子问题时，动态规划才管用。
## 总结
    1.动态规划可帮助你在给定约束条件下找到最优解。在背包问题中，你必须在背包容量给定的情况下，偷到价值最高的商品。
    2.在问题可分解为彼此独立且离散的子问题时，就可使用动态规划来解决。要设计出动态规划解决方案可能很难，这正是本节要介绍的。下面是一些通用的小贴士。
    3.每种动态规划解决方案都涉及网格。
    4.单元格中的值通常就是你要优化的值。在前面的背包问题中，单元格的值为商品的价值。
    5.每个单元格都是一个子问题，因此你应考虑如何将问题分成子问题，这有助于你找出网格的坐标轴。
    1.需要在给定约束条件下优化某种指标时，动态规划很有用。
    2.问题可分解为离散子问题时，可使用动态规划来解决。
    3.每种动态规划解决方案都涉及网格。
    4.单元格中的值通常就是你要优化的值。
    5.每个单元格都是一个子问题，因此你需要考虑如何将问题分解为子问题。❑ 没有放之四海皆准的计算动态规划解决方案的公式。
